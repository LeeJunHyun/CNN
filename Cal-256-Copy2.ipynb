{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from copy import copy\n",
    "import os\n",
    "from scipy.misc import toimage\n",
    "from scipy import signal\n",
    "from scipy.misc import imread, imsave, imresize\n",
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.pyplot as plt\n",
    "# imshow(image)\n",
    "# plt.show()\n",
    "# toimage(image).show()\n",
    "\n",
    "tf.set_random_seed(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gpu_config = tf.ConfigProto(device_count={'GPU':1})  # only use GPU no.1 change this!\n",
    "gpu_config.gpu_options.allow_growth = True # only use required resource(memory)\n",
    "gpu_config.gpu_options.per_process_gpu_memory_fraction = 0.5 # restrict to 50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def search(dirname):\n",
    "    filenames = os.listdir(dirname)\n",
    "    full_filenames = []\n",
    "    for filename in filenames:\n",
    "        full_filename = os.path.join(dirname, filename)\n",
    "        full_filenames.append(full_filename)\n",
    "        #print (full_filename)\n",
    "    return full_filenames\n",
    "\"\"\"\n",
    "def Image_search(Image_dir,num_image):\n",
    "    images=[]\n",
    "    for i in range(num_image):\n",
    "        image_raw = imread(Image_dir[i])\n",
    "        image = imresize(image_raw,(300,300))\n",
    "        images.append(image)\n",
    "    return images\n",
    "\"\"\"\n",
    "\n",
    "def Image_search(Image_dir,num_image):\n",
    "    images=np.zeros([1,200*200*3])\n",
    "    for i in range(num_image):\n",
    "        image_raw = imread(Image_dir[i])\n",
    "        image = imresize(image_raw,(200,200))\n",
    "        image = np.reshape(image,(1,200*200*3))/255\n",
    "        image = image # - np.mean(image)\n",
    "        images = np.append(images,image,axis=0)\n",
    "    return images[1:]\n",
    "\n",
    "def label2onehot(label,num_class):\n",
    "    one_hot = np.zeros((len(label),num_class))\n",
    "    for idx,l in enumerate(label):\n",
    "        one_hot[idx,l] = 1\n",
    "    return one_hot\n",
    "\n",
    "search(\"/home/junhyun/Data/Dataset\")\n",
    "\n",
    "Total_images = np.zeros([1,200*200*3])\n",
    "Total_labels = np.zeros([1])\n",
    "\n",
    "Image_dir = search(\"/home/junhyun/Data/Dataset/Airplanes\")\n",
    "airplanes_images = Image_search(Image_dir,350)\n",
    "airplanes_labels = np.ones(len(airplanes_images))*0\n",
    "\n",
    "Total_images = np.append(Total_images,airplanes_images,axis=0)\n",
    "Total_labels = np.append(Total_labels,airplanes_labels,axis=0)\n",
    "\n",
    "\n",
    "Image_dir = search(\"/home/junhyun/Data/Dataset/Binocular\")\n",
    "binocular_images = Image_search(Image_dir,len(Image_dir))\n",
    "binocular_labels = np.ones(len(binocular_images))*1\n",
    "\n",
    "Total_images = np.append(Total_images,binocular_images,axis=0)\n",
    "Total_labels = np.append(Total_labels,binocular_labels,axis=0)\n",
    "\n",
    "Image_dir = search(\"/home/junhyun/Data/Dataset/grapes\")\n",
    "grapes_images = Image_search(Image_dir,len(Image_dir))\n",
    "grapes_labels = np.ones(len(grapes_images))*2\n",
    "\n",
    "Total_images = np.append(Total_images,grapes_images,axis=0)\n",
    "Total_labels = np.append(Total_labels,grapes_labels,axis=0)\n",
    "\n",
    "Image_dir = search(\"/home/junhyun/Data/Dataset/Leopards\")\n",
    "leopards_images = Image_search(Image_dir,len(Image_dir))\n",
    "leopards_labels = np.ones(len(leopards_images))*3\n",
    "\n",
    "Total_images = np.append(Total_images,leopards_images,axis=0)\n",
    "Total_labels = np.append(Total_labels,leopards_labels,axis=0)\n",
    "\n",
    "Image_dir = search(\"/home/junhyun/Data/Dataset/Motorbikes\")\n",
    "motorbikes_images = Image_search(Image_dir,350)\n",
    "motorbikes_labels = np.ones(len(motorbikes_images))*4\n",
    "\n",
    "Total_images = np.append(Total_images,motorbikes_images,axis=0)\n",
    "Total_labels = np.append(Total_labels,motorbikes_labels,axis=0)\n",
    "\n",
    "Image_dir = search(\"/home/junhyun/Data/Dataset/watch\")\n",
    "watch_images = Image_search(Image_dir,len(Image_dir))\n",
    "watch_labels = np.ones(len(watch_images))*5\n",
    "\n",
    "Total_images = np.append(Total_images,watch_images,axis=0)\n",
    "Total_labels = np.append(Total_labels,watch_labels,axis=0)\n",
    "\n",
    "Image_dir = search(\"/home/junhyun/Data/Dataset/Faces_easy\")\n",
    "faces_easy_images = Image_search(Image_dir,350)\n",
    "faces_easy_labels = np.ones(len(faces_easy_images))*6\n",
    "\n",
    "Total_images = np.append(Total_images,faces_easy_images,axis=0)[1:]\n",
    "Total_labels = np.append(Total_labels,faces_easy_labels,axis=0)[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Total_one_hot = Total_labels.astype(int)\n",
    "Total_one_hot = label2onehot(np.transpose(Total_one_hot),7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shuffle_img_label(img,label):\n",
    "    tmp_img = np.zeros_like(img)\n",
    "    tmp_label = np.zeros_like(label)\n",
    "    Order = list(range(0,len(label)))\n",
    "    np.random.shuffle(Order)\n",
    "    for idx,order in enumerate(Order):\n",
    "        tmp_img[idx] = img[order]\n",
    "        tmp_label[idx] = label[order]\n",
    "    return tmp_img, tmp_label\n",
    "\n",
    "Shuffle_image, Shuffle_label = shuffle_img_label(Total_images,Total_one_hot)\n",
    "# Shuffle_image, Shuffle_label = shuffle_img_label(Total_images,Total_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RGB_flip_LeftRight(Img):\n",
    "    \n",
    "    Img_clone = copy(Img)\n",
    "    Flip_Img_result = np.zeros_like(Img_clone)\n",
    "\n",
    "    for i in range(Img_clone.shape[0]):\n",
    "        Flip_Img = np.reshape(Img_clone[i,:],[200,200,3])\n",
    "    \n",
    "        for k in range(3):\n",
    "            for j in range(Flip_Img.shape[0]):            \n",
    "                Flip_Img[j,:,k] = Flip_Img[j,::-1,k]\n",
    "    \n",
    "    Flip_Img = np.reshape(Flip_Img,[1,200*200*3])\n",
    "    Flip_Img_result[i,:] = Flip_Img\n",
    "\n",
    "    return Flip_Img_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Train_images = Shuffle_image[0:1500]\n",
    "Train_one_hot = Shuffle_label[0:1500]\n",
    "\n",
    "Flip_images = RGB_flip_LeftRight(Train_images)\n",
    "\n",
    "Train_images = np.append(Train_images,Flip_images,axis=0)\n",
    "Train_one_hot = np.append(Train_one_hot,Train_one_hot,axis=0)\n",
    "\n",
    "\n",
    "Test_images = Shuffle_image[1500:]\n",
    "Test_one_hot = Shuffle_label[1500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, sess, name):\n",
    "        self.sess=sess\n",
    "        self.name=name\n",
    "        self._build_net()\n",
    "        \n",
    "    def _build_net(self):\n",
    "        self.training= tf.placeholder(tf.bool)\n",
    "        self.X = tf.placeholder(tf.float32,[None, 200*200*3])\n",
    "        X_img = tf.reshape(self.X, [-1,200,200,3])\n",
    "        self.Y = tf.placeholder(tf.float32,[None,7])\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.W1 = tf.Variable(tf.random_normal([3, 3, 3, 64], stddev=0.01))\n",
    "        \n",
    "        L1 = tf.nn.conv2d(X_img, self.W1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "#         L1 = tf.nn.relu(L1)\n",
    "        \n",
    "        \n",
    "#         self.conv_W = tf.layers.conv2d(inputs = X_img, \\\n",
    "#                                        filters = 64, \\\n",
    "#                                        kernel_size=[3, 3], \\\n",
    "#                                        padding = \"SAME\",\\\n",
    "#                                        activation=tf.nn.relu,\\\n",
    "#                                        name = \"conv_W\", \\\n",
    "#                                        kernel_initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "        \n",
    "        conv1 = tf.layers.conv2d(inputs = L1, filters = 64, kernel_size=[3, 3], padding = \"SAME\",\\\n",
    "                                 activation=tf.nn.relu,kernel_initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "        conv12 = tf.layers.conv2d(inputs = conv1, filters = 64, kernel_size=[3, 3], padding = \"SAME\",\\\n",
    "                                  activation=tf.nn.relu,kernel_initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "\n",
    "        pool1 = tf.layers.max_pooling2d(inputs=conv12, pool_size = [2, 2], padding=\"SAME\", strides=2)\n",
    "#         drop1 = tf.layers.dropout(inputs=pool1, rate=0.7, training = self.training)\n",
    "        \n",
    "#         conv2 = tf.layers.conv2d(inputs = pool1, filters = 128, kernel_size=[3, 3], padding = \"SAME\", \\\n",
    "#                                  activation=tf.nn.relu,kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "#         conv22 = tf.layers.conv2d(inputs = conv2, filters = 128, kernel_size=[3, 3], padding = \"SAME\", \\\n",
    "#                                   activation=tf.nn.relu,kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "#         conv23 = tf.layers.conv2d(inputs = conv2, filters = 128, kernel_size=[3, 3], padding = \"SAME\", \\\n",
    "#                                   activation=tf.nn.relu,kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "#         pool2 = tf.layers.max_pooling2d(inputs=conv23, pool_size = [2, 2], padding=\"SAME\", strides=2)\n",
    "#         drop2 = tf.layers.dropout(inputs=pool2, rate=0.7, training = self.training)\n",
    "        \n",
    "        conv3 = tf.layers.conv2d(inputs = pool1, filters = 128, kernel_size=[3, 3], padding = \"SAME\", \\\n",
    "                                 activation=tf.nn.relu,kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "        conv32 = tf.layers.conv2d(inputs = conv3, filters = 128, kernel_size=[3, 3], padding = \"SAME\", \\\n",
    "                                  activation=tf.nn.relu,kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "        conv33 = tf.layers.conv2d(inputs = conv3, filters = 128, kernel_size=[3, 3], padding = \"SAME\", \\\n",
    "                                  activation=tf.nn.relu,kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "#         pool3 = tf.layers.max_pooling2d(inputs=conv33, pool_size = [2, 2], padding=\"SAME\", strides=2)\n",
    "#         drop3 = tf.layers.dropout(inputs=pool3, rate=0.7, training = self.training)\n",
    "        \n",
    "        conv4 = tf.layers.conv2d(inputs = conv33, filters = 128, kernel_size=[3, 3], padding = \"SAME\", \\\n",
    "                                 activation=tf.nn.relu,kernel_initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "        conv42 = tf.layers.conv2d(inputs = conv4, filters = 256, kernel_size=[3, 3], padding = \"SAME\", \\\n",
    "                                  activation=tf.nn.relu,kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "#         conv43 = tf.layers.conv2d(inputs = conv4, filters = 128, kernel_size=[3, 3], padding = \"SAME\", \\\n",
    "#                                   activation=tf.nn.relu,kernel_initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "        pool4 = tf.layers.max_pooling2d(inputs=conv42, pool_size = [2, 2], padding=\"SAME\", strides=2)\n",
    "#         drop4 = tf.layers.dropout(inputs=pool4, rate=0.7, training = self.training)\n",
    "        \n",
    "        conv5 = tf.layers.conv2d(inputs = pool4, filters = 256, kernel_size=[3, 3], padding = \"SAME\", \\\n",
    "                                 activation=tf.nn.relu,kernel_initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "        conv52 = tf.layers.conv2d(inputs = conv5, filters = 256, kernel_size=[3, 3], padding = \"SAME\", \\\n",
    "                                  activation=tf.nn.relu,kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "#         conv53 = tf.layers.conv2d(inputs = conv5, filters = 256, kernel_size=[3, 3], padding = \"SAME\", \\\n",
    "#                                   activation=tf.nn.relu,kernel_initializer=tf.contrib.layers.xavier_initializer_conv2d())        \n",
    "        pool5 = tf.layers.max_pooling2d(inputs=conv52, pool_size = [2, 2], padding=\"SAME\", strides=2)\n",
    "#         drop5 = tf.layers.dropout(inputs=pool5, rate=0.7, training = self.training)\n",
    "             \n",
    "        conv6 = tf.layers.conv2d(inputs = pool5, filters = 128, kernel_size=[3, 3], padding = \"SAME\", \\\n",
    "                                 activation=tf.nn.relu,kernel_initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "#         conv62 = tf.layers.conv2d(inputs = conv6, filters = 512, kernel_size=[3, 3], padding = \"SAME\", activation=tf.nn.relu,kernel_initializer=tf.contrib.layers.variance_scaling_initializer(),kernel_regularizer=tf.contrib.layers.l2_regularizer(0.01))\n",
    "#         conv63 = tf.layers.conv2d(inputs = conv62, filters = 512, kernel_size=[3, 3], padding = \"SAME\", activation=tf.nn.relu,kernel_initializer=tf.contrib.layers.variance_scaling_initializer(),kernel_regularizer=tf.contrib.layers.l2_regularizer(0.01))        \n",
    "        pool6 = tf.layers.max_pooling2d(inputs=conv6, pool_size = [2, 2], padding=\"SAME\", strides=2)\n",
    "#         drop6 = tf.layers.dropout(inputs=pool6, rate=0.7, training = self.training)\n",
    "             \n",
    "        \n",
    "        flat = tf.reshape(pool6,[-1,13*13*128])\n",
    "        dense4 = tf.layers.dense(inputs=flat,units=4096,activation=tf.nn.relu,\\\n",
    "                                 kernel_initializer = tf.contrib.layers.xavier_initializer(),\\\n",
    "                                 kernel_regularizer=tf.contrib.layers.l2_regularizer(0.001))\n",
    "        drop4 = tf.layers.dropout(inputs=dense4,rate=0.4,training = self.training)\n",
    "        batch4 = tf.layers.batch_normalization(drop4,training= True)\n",
    "        \n",
    "        dense5 = tf.layers.dense(inputs=batch4,units=4096,activation=tf.nn.relu,\\\n",
    "                                 kernel_initializer = tf.contrib.layers.xavier_initializer(),\\\n",
    "                                 kernel_regularizer=tf.contrib.layers.l2_regularizer(0.001))\n",
    "        drop5 = tf.layers.dropout(inputs=dense5,rate=0.4,training = self.training)\n",
    "        batch5 = tf.layers.batch_normalization(drop5,training= True)\n",
    "\n",
    "\n",
    "        dense6 = tf.layers.dense(inputs=batch5,units=1000,activation=tf.nn.relu,\\\n",
    "                                 kernel_initializer = tf.contrib.layers.xavier_initializer(),\\\n",
    "                                 kernel_regularizer=tf.contrib.layers.l2_regularizer(0.001))\n",
    "        drop6 = tf.layers.dropout(inputs=dense6,rate=0.4,training = self.training)\n",
    "        batch6 = tf.layers.batch_normalization(drop6,training= True)\n",
    "        \n",
    "        self.logits = tf.layers.dense(inputs=batch6,units=7,\\\n",
    "                                      kernel_initializer = tf.contrib.layers.xavier_initializer(),\\\n",
    "                                      kernel_regularizer=tf.contrib.layers.l2_regularizer(0.001))\n",
    "        \n",
    "        self.cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=self.logits,labels=self.Y))\n",
    "        self.optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(self.cost)\n",
    "        self.prediction = tf.argmax(self.logits,1)\n",
    "        self.correct_prediction = tf.equal(self.prediction,tf.argmax(self.Y,1))\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(self.correct_prediction,tf.float32))\n",
    "        \n",
    "        self.gr = tf.get_default_graph()\n",
    "        \n",
    "    def predict(self,x_test,training=False):\n",
    "        return self.sess.run(self.logits,feed_dict={self.X:x_test, self.training:training})\n",
    "        \n",
    "    def get_accuracy(self, x_test, y_test, training=False):\n",
    "        return self.sess.run(self.accuracy,feed_dict={self.X:x_test, self.Y:y_test, self.training:training})\n",
    "        \n",
    "    def train(self,x_test,y_test,training=True):\n",
    "        return self.sess.run([self.cost,self.optimizer],feed_dict={self.X:x_test,self.Y:y_test, self.training:training})\n",
    "    \n",
    "    def get_weight(self):\n",
    "        Weight = sess.run(self.W1)\n",
    "        return Weight\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs=500\n",
    "batch_size=10\n",
    "learning_rate=0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session(config=gpu_config)\n",
    "\n",
    "models=[]\n",
    "num_models=1\n",
    "for m in range(num_models):\n",
    "    models.append(Model(sess,\"model\"+str(m)))\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning start!!\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-6b6815f4a03d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mm_idx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_xs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_ys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0mavg_cost_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtotal_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"epoch : \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"%04d\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" cost : \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_cost_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-6ef815b2378d>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, x_test, y_test, training)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/junhyun/junhyunenv/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/junhyun/junhyunenv/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/junhyun/junhyunenv/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/junhyun/junhyunenv/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1137\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/junhyun/junhyunenv/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Learning start!!\")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    learning_rate = learning_rate*0.995\n",
    "    avg_cost_list = np.zeros(len(models))\n",
    "    total_batch = int(len(Train_one_hot)/batch_size)\n",
    "    for i in range(total_batch):\n",
    "        batch_xs = Train_images[i*batch_size:(i+1)*batch_size]\n",
    "        batch_ys = Train_one_hot[i*batch_size:(i+1)*batch_size]\n",
    "        \n",
    "        for m_idx,m in enumerate(models):\n",
    "            c,_ = m.train(batch_xs,batch_ys)\n",
    "            avg_cost_list[m_idx] += c/total_batch\n",
    "    print(\"epoch : \", \"%04d\"%(epoch+1), \" cost : \", avg_cost_list)\n",
    "    \n",
    "print(\"Learning finished!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 'Accuracy = ', 0.44140625)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_batch_size =4\n",
    "\n",
    "total_batch = int(Test_images.shape[0]/test_batch_size)\n",
    "acc = 0\n",
    "for m_idx,m in enumerate(models):\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs = Test_images[i*test_batch_size:(i+1)*test_batch_size]\n",
    "        batch_ys = Test_one_hot[i*test_batch_size:(i+1)*test_batch_size]\n",
    "        acc += m.get_accuracy(batch_xs,batch_ys)\n",
    "\n",
    "    print(m_idx, \"Accuracy = \", float(acc)/float(total_batch))\n",
    "    \n",
    "    \n",
    "\n",
    "# test_size = len(Test_one_hot)\n",
    "# prediction = np.zeros(test_size*7).reshape(test_size,7)\n",
    "\n",
    "# for m_idx,m in enumerate(models):\n",
    "#     print(m_idx, \"Accuracy = \", m.get_accuracy(Test_images,Test_one_hot))\n",
    "#     p = m.predict(Test_images)\n",
    "#     prediction +=p\n",
    "\n",
    "# ensemble_correct = tf.equal(tf.argmax(prediction,1),tf.argmax(Test_one_hot,1))\n",
    "# ensemble_accuracy = tf.reduce_mean(tf.cast(ensemble_correct,tf.float32))\n",
    "\n",
    "# print(\"Ensemble Accuracy = \", sess.run(ensemble_accuracy) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  7.79233813e-01,  -2.07577419e+00,  -1.21688664e+00,\n",
       "          2.02715278e+00,  -5.10181379e+00,   1.85337067e-01,\n",
       "          2.86026073e+00],\n",
       "       [ -1.07026768e+01,   3.24990845e+00,   4.11540604e+00,\n",
       "          2.83889604e+00,  -5.89954567e+00,   7.04104805e+00,\n",
       "          1.15791607e+00],\n",
       "       [  1.70338428e+00,  -1.26990891e+00,   2.83647752e+00,\n",
       "         -2.50867677e+00,   1.12539892e+01,  -6.80820704e+00,\n",
       "         -1.52159166e+00],\n",
       "       [  5.92615747e+00,  -5.09203434e+00,  -2.85745239e+00,\n",
       "          5.29753745e-01,  -7.50579214e+00,   3.79447389e+00,\n",
       "          3.34223294e+00],\n",
       "       [  7.21456170e-01,  -5.07615566e+00,  -1.89143491e+00,\n",
       "         -9.68863010e+00,   1.76491165e+01,  -3.97123766e+00,\n",
       "         -1.30406737e+00],\n",
       "       [ -4.03597498e+00,  -2.32412434e+00,   6.61122739e-01,\n",
       "         -1.55065084e+00,  -9.07968235e+00,   1.75308590e+01,\n",
       "         -4.34001398e+00],\n",
       "       [  7.79233813e-01,  -2.07577419e+00,  -1.21688664e+00,\n",
       "          2.02715278e+00,  -5.10181379e+00,   1.85337067e-01,\n",
       "          2.86026073e+00],\n",
       "       [ -1.67537594e+01,   2.14196944e+00,  -2.93391848e+00,\n",
       "          1.55953674e+01,  -7.54244041e+00,   1.07885723e+01,\n",
       "         -8.75132370e+00],\n",
       "       [  8.29668045e+00,   1.94333286e+01,   2.54524541e+00,\n",
       "         -1.44485903e+01,  -1.12445383e+01,   5.00169420e+00,\n",
       "         -1.26262560e+01],\n",
       "       [  1.77480578e+00,  -1.64738417e+00,  -1.20039999e+00,\n",
       "          3.13198543e+00,  -8.44110107e+00,   6.16943359e+00,\n",
       "         -2.53184295e+00],\n",
       "       [  5.27302837e+00,   2.12770581e+00,  -5.32032490e+00,\n",
       "         -1.99866760e+00,  -9.40067005e+00,   6.74925327e+00,\n",
       "          1.14655519e+00],\n",
       "       [ -3.27335095e+00,   3.17030144e+00,  -6.05287254e-01,\n",
       "         -4.64507484e+00,  -6.13212442e+00,   1.44041557e+01,\n",
       "         -3.47265744e+00],\n",
       "       [  1.09028025e+01,  -3.66991353e+00,  -3.19365549e+00,\n",
       "         -1.35132015e+00,  -2.67436624e+00,   8.34207118e-01,\n",
       "          2.32568771e-01],\n",
       "       [  3.06262195e-01,   6.77516222e+00,   3.60166550e+00,\n",
       "         -9.54783058e+00,   1.38049517e+01,  -2.39870667e+00,\n",
       "         -1.17038927e+01],\n",
       "       [  1.45706301e+01,  -6.69747210e+00,  -3.56492043e+00,\n",
       "         -6.67786121e-01,   1.01887536e+00,  -1.34533679e+00,\n",
       "         -3.73434973e+00],\n",
       "       [ -2.06235147e+00,  -2.27698445e+00,  -2.70256138e+00,\n",
       "          6.88420630e+00,  -5.47467566e+00,   2.77961063e+00,\n",
       "          2.69327426e+00],\n",
       "       [  1.06282413e+00,  -5.62641525e+00,  -1.06481099e+00,\n",
       "         -6.00299788e+00,   1.49492846e+01,  -3.51462388e+00,\n",
       "          4.81867939e-01],\n",
       "       [ -4.14638948e+00,   2.39449859e+00,   4.79525948e+00,\n",
       "          2.72021008e+00,  -7.26069260e+00,  -4.39369202e+00,\n",
       "          5.75034618e+00],\n",
       "       [ -2.67883968e+00,  -1.25139058e+00,   1.28734274e+01,\n",
       "          2.13946223e+00,  -8.97764015e+00,  -8.01688433e-02,\n",
       "         -3.44533849e+00],\n",
       "       [ -9.66491640e-01,  -6.76684666e+00,  -1.56329048e+00,\n",
       "         -5.85626554e+00,   1.53702669e+01,  -2.49781871e+00,\n",
       "          2.26644158e+00],\n",
       "       [ -3.81368804e+00,   1.89959419e+00,  -1.59262753e+00,\n",
       "         -5.94790578e-01,  -7.17864466e+00,   2.73183942e+00,\n",
       "          8.87657452e+00],\n",
       "       [  2.59157687e-01,  -3.10410082e-01,   6.76100433e-01,\n",
       "          7.84082651e-01,  -7.56432390e+00,   7.18743980e-01,\n",
       "          3.95386338e+00],\n",
       "       [  3.64528537e-01,  -2.27793455e+00,  -1.40118134e+00,\n",
       "         -8.47902203e+00,   1.57906675e+01,  -5.95268583e+00,\n",
       "         -3.55808049e-01],\n",
       "       [  1.59398925e+00,  -2.55251718e+00,  -2.48945737e+00,\n",
       "         -3.28880954e+00,   1.18020296e+01,  -1.53724098e+00,\n",
       "         -3.71428668e-01],\n",
       "       [ -6.73415613e+00,   8.11030102e+00,   1.35089719e+00,\n",
       "         -2.03267395e-01,  -3.70784545e+00,   6.09652233e+00,\n",
       "         -6.95921087e+00],\n",
       "       [  8.24532127e+00,  -2.19404888e+00,  -2.77770352e+00,\n",
       "          2.43879128e+00,   7.06761885e+00,  -4.08666563e+00,\n",
       "         -4.75719786e+00],\n",
       "       [  3.96415758e+00,   2.98366261e+00,  -5.81817579e+00,\n",
       "          1.21670465e+01,  -6.33279324e+00,  -5.05484104e+00,\n",
       "         -2.01879859e+00],\n",
       "       [ -1.41545594e+00,  -5.17377615e+00,   6.63638401e+00,\n",
       "          3.83754182e+00,   1.05431318e+00,  -1.33179693e+01,\n",
       "          5.46997929e+00],\n",
       "       [ -7.64330447e-01,   3.90119600e+00,   4.36237621e+00,\n",
       "         -1.46589384e+01,   1.68074646e+01,  -9.34279823e+00,\n",
       "         -6.06207657e+00],\n",
       "       [ -8.54197443e-01,   4.67467219e-01,   1.29333496e+00,\n",
       "          1.95969331e+00,  -4.79219055e+00,  -2.79336095e-01,\n",
       "          1.70033062e+00],\n",
       "       [  4.80599070e+00,   3.01830912e+00,   1.36310997e+01,\n",
       "          2.48774901e-01,  -1.12589798e+01,  -8.53373528e-01,\n",
       "         -1.23209448e+01],\n",
       "       [  3.03537345e+00,  -2.04796910e+00,  -4.53884029e+00,\n",
       "          5.81549358e+00,  -5.74832582e+00,   4.57693005e+00,\n",
       "         -8.29696834e-01],\n",
       "       [  1.08028781e+00,  -4.40429544e+00,  -1.01268935e+00,\n",
       "         -6.50852537e+00,   1.48571968e+01,  -4.77896261e+00,\n",
       "          4.63318944e-01],\n",
       "       [ -2.21639442e+00,   2.24849749e+00,  -8.38226616e-01,\n",
       "          1.51753199e+00,  -4.81799984e+00,   3.79397094e-01,\n",
       "          2.87367153e+00],\n",
       "       [  3.81999540e+00,  -8.89295387e+00,  -6.44406033e+00,\n",
       "         -5.46652794e+00,  -7.46467113e+00,  -8.32258701e+00,\n",
       "          1.59910364e+01],\n",
       "       [ -2.74405050e+00,   2.91997242e+00,  -1.04707122e+00,\n",
       "         -9.65022027e-01,  -9.15997124e+00,   4.87887478e+00,\n",
       "          5.65767527e+00],\n",
       "       [ -2.10373211e+01,   5.42979002e+00,   3.51981950e+00,\n",
       "          3.65086508e+00,   9.03760815e+00,   1.92628992e+00,\n",
       "         -1.89330614e+00],\n",
       "       [ -4.43250608e+00,  -7.98329401e+00,   5.16833210e+00,\n",
       "         -1.54655910e+00,  -1.69122810e+01,   2.13360577e+01,\n",
       "         -2.89013624e+00],\n",
       "       [ -6.76810265e+00,  -3.39763665e+00,   2.89495802e+00,\n",
       "         -5.19329691e+00,   1.86988945e+01,   2.15497255e+00,\n",
       "         -1.18404531e+01],\n",
       "       [ -5.18240631e-01,  -7.23764610e+00,   1.88095188e+00,\n",
       "          2.09478930e-01,  -1.89273014e+01,   4.40980196e+00,\n",
       "          1.67932816e+01],\n",
       "       [  2.37483072e+00,  -1.71850765e+00,  -1.63707852e+00,\n",
       "         -4.55647802e+00,   1.35993481e+01,  -1.71124482e+00,\n",
       "         -3.88735795e+00],\n",
       "       [ -1.28590012e+00,  -1.89876878e+00,  -5.79348660e+00,\n",
       "          4.69893742e+00,  -6.30804348e+00,   3.41551733e+00,\n",
       "          4.71016836e+00],\n",
       "       [ -4.27629995e+00,  -1.06376686e+01,   2.05230255e+01,\n",
       "         -1.93314874e+00,  -1.21496344e+01,   1.01753139e+01,\n",
       "         -1.52065630e+01],\n",
       "       [ -6.75229311e+00,   1.11151419e+01,   7.95672941e+00,\n",
       "         -4.86283875e+00,  -1.05294838e+01,   4.34079695e+00,\n",
       "         -1.70406330e+00],\n",
       "       [ -3.77154422e+00,   3.36377358e+00,  -5.94871235e+00,\n",
       "          8.82814765e-01,  -4.62437773e+00,   3.15076566e+00,\n",
       "          1.16301126e+01],\n",
       "       [ -9.10662174e-01,   1.86300430e+01,   2.51689339e+00,\n",
       "         -7.28172255e+00,  -8.43739891e+00,  -6.25973523e-01,\n",
       "         -3.69065714e+00],\n",
       "       [ -5.81858829e-02,  -8.05128288e+00,  -1.08809724e-01,\n",
       "         -2.77306843e+00,  -1.51239138e+01,   1.84293282e+00,\n",
       "          2.25348625e+01],\n",
       "       [  1.03215466e+01,   4.32070732e+00,  -7.79074430e+00,\n",
       "         -1.95499492e+00,   1.19636850e+01,  -8.08500671e+00,\n",
       "         -6.96963978e+00],\n",
       "       [  1.70839081e+01,   2.33484888e+00,  -1.10645647e+01,\n",
       "         -2.83522749e+00,   7.00928450e-01,  -7.00893307e+00,\n",
       "         -6.28169537e+00],\n",
       "       [ -6.30299854e+00,  -3.52288127e+00,   1.25210886e+01,\n",
       "          1.11266508e+01,   1.33824849e+00,  -1.04515991e+01,\n",
       "         -2.92802334e+00],\n",
       "       [  8.60921288e+00,  -1.31234145e+00,  -5.58216047e+00,\n",
       "         -1.78557262e-02,   3.37832212e+00,  -1.66764772e+00,\n",
       "         -1.05264866e+00],\n",
       "       [  7.79233813e-01,  -2.07577419e+00,  -1.21688664e+00,\n",
       "          2.02715278e+00,  -5.10181379e+00,   1.85337067e-01,\n",
       "          2.86026073e+00],\n",
       "       [ -3.01791382e+00,  -3.43766356e+00,   2.21266103e+00,\n",
       "          7.09429502e+00,  -1.10292778e+01,   8.17793179e+00,\n",
       "         -1.82260358e+00],\n",
       "       [  1.67905273e+01,  -3.79981399e+00,  -2.65210676e+00,\n",
       "         -1.25270357e+01,   3.39049792e+00,  -6.27256298e+00,\n",
       "         -2.62072754e+00],\n",
       "       [ -6.54523075e-01,  -1.38756561e+00,  -9.09745276e-01,\n",
       "          2.03918076e+00,  -5.55806875e+00,   1.58040404e+00,\n",
       "          2.80847692e+00],\n",
       "       [  1.15156593e+01,  -7.50405312e-01,  -3.23880601e+00,\n",
       "         -1.25010405e+01,   7.18384743e+00,  -4.08211756e+00,\n",
       "         -4.35734320e+00],\n",
       "       [ -2.73760080e+00,  -6.20218158e-01,   9.03478682e-01,\n",
       "         -3.03722382e-01,   7.25433111e-01,  -9.73820877e+00,\n",
       "          1.57356138e+01],\n",
       "       [  9.88883114e+00,  -6.36787319e+00,  -3.24432683e+00,\n",
       "         -5.61351895e-01,   5.17730904e+00,  -3.12691426e+00,\n",
       "         -1.62997186e-01],\n",
       "       [ -2.06389260e+00,  -3.99791384e+00,   8.03936577e+00,\n",
       "         -3.41732669e+00,  -1.33344054e+00,   1.22714663e+01,\n",
       "         -9.25564003e+00],\n",
       "       [ -9.12321091e-01,   1.11721337e+00,   3.37534785e+00,\n",
       "          9.72015500e-01,  -5.43180275e+00,  -9.11135018e-01,\n",
       "         -4.04669344e-01]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models[0].predict(Test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot evaluate tensor using `eval()`: No default session is registered. Use `with sess.as_default()` or pass an explicit session to `eval(session=sess)`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-3aee89120505>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mconvWeight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mOrigin_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTest_image\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mWeight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvWeight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-d8452e3c09ad>\u001b[0m in \u001b[0;36mget_weight\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0mWeight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tensor_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'conv_W/kernel:0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mWeight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/junhyun/junhyunenv/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m     \"\"\"\n\u001b[0;32m--> 606\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/junhyun/junhyunenv/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[0;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   3912\u001b[0m     \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3913\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msession\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3914\u001b[0;31m       raise ValueError(\"Cannot evaluate tensor using `eval()`: No default \"\n\u001b[0m\u001b[1;32m   3915\u001b[0m                        \u001b[0;34m\"session is registered. Use `with \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3916\u001b[0m                        \u001b[0;34m\"sess.as_default()` or pass an explicit session to \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot evaluate tensor using `eval()`: No default session is registered. Use `with sess.as_default()` or pass an explicit session to `eval(session=sess)`"
     ]
    }
   ],
   "source": [
    "convWeight = sess.run(tf.transpose(models[0].get_weight()))\n",
    "Origin_data = Test_image[15][0:1024]\n",
    "Weight = convWeight[3][0]\n",
    "32*32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Origin_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Origin_image = np.reshape(Origin_data,[32,32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.misc\n",
    "\n",
    "i_width = 300\n",
    "i_height = 300\n",
    "\n",
    "Big_image = scipy.misc.imresize(Origin_image, (i_height, i_width))\n",
    "print(Big_image.shape)\n",
    "Origin_image = Big_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "toimage(Origin_image).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Conv_image = signal.convolve2d(Origin_image,Weight,'same')\n",
    "\n",
    "Conv_image -= Conv_image.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "toimage(Conv_image).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(Origin_image.max())\n",
    "print(Origin_image.min())\n",
    "\n",
    "print(Conv_image.max())\n",
    "print(Conv_image.min())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Edge_image = Origin_image-3*Conv_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(Edge_image.max())\n",
    "print(Edge_image.min())\n",
    "Edge_image -= Edge_image.min()\n",
    "Edge_image = Edge_image/Edge_image.max()\n",
    "print(Edge_image.max())\n",
    "print(Edge_image.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "toimage(Edge_image).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "toimage(Weight).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow kernel",
   "language": "python",
   "name": "tfkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
