{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from copy import copy\n",
    "import os\n",
    "from scipy.misc import toimage\n",
    "from scipy import signal\n",
    "from scipy.misc import imread, imsave, imresize\n",
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.pyplot as plt\n",
    "# imshow(image)\n",
    "# plt.show()\n",
    "# toimage(image).show()\n",
    "\n",
    "tf.set_random_seed(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gpu_config = tf.ConfigProto(device_count={'GPU':1})  # only use GPU no.1 change this!\n",
    "gpu_config.gpu_options.allow_growth = True # only use required resource(memory)\n",
    "gpu_config.gpu_options.per_process_gpu_memory_fraction = 0.4 # restrict to 50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def search(dirname):\n",
    "    filenames = os.listdir(dirname)\n",
    "    full_filenames = []\n",
    "    for filename in filenames:\n",
    "        full_filename = os.path.join(dirname, filename)\n",
    "        full_filenames.append(full_filename)\n",
    "        #print (full_filename)\n",
    "    return full_filenames\n",
    "\"\"\"\n",
    "def Image_search(Image_dir,num_image):\n",
    "    images=[]\n",
    "    for i in range(num_image):\n",
    "        image_raw = imread(Image_dir[i])\n",
    "        image = imresize(image_raw,(300,300))\n",
    "        images.append(image)\n",
    "    return images\n",
    "\"\"\"\n",
    "\n",
    "def Image_search(Image_dir,num_image):\n",
    "    images=np.zeros([1,200*200*3])\n",
    "    for i in range(num_image):\n",
    "        image_raw = imread(Image_dir[i])\n",
    "        image = imresize(image_raw,(200,200))\n",
    "        image = np.reshape(image,(1,200*200*3))/255\n",
    "        image = image # - np.mean(image)\n",
    "        images = np.append(images,image,axis=0)\n",
    "    return images[1:]\n",
    "\n",
    "def label2onehot(label,num_class):\n",
    "    one_hot = np.zeros((len(label),num_class))\n",
    "    for idx,l in enumerate(label):\n",
    "        one_hot[idx,l] = 1\n",
    "    return one_hot\n",
    "\n",
    "search(\"/home/junhyun/Data/Dataset\")\n",
    "\n",
    "Total_images = np.zeros([1,200*200*3])\n",
    "Total_labels = np.zeros([1])\n",
    "\n",
    "Image_dir = search(\"/home/junhyun/Data/Dataset/Airplanes\")\n",
    "airplanes_images = Image_search(Image_dir,300)\n",
    "airplanes_labels = np.ones(len(airplanes_images))*0\n",
    "\n",
    "Total_images = np.append(Total_images,airplanes_images,axis=0)\n",
    "Total_labels = np.append(Total_labels,airplanes_labels,axis=0)\n",
    "\n",
    "\n",
    "Image_dir = search(\"/home/junhyun/Data/Dataset/Binocular\")\n",
    "binocular_images = Image_search(Image_dir,len(Image_dir))\n",
    "binocular_labels = np.ones(len(binocular_images))*1\n",
    "\n",
    "Total_images = np.append(Total_images,binocular_images,axis=0)\n",
    "Total_labels = np.append(Total_labels,binocular_labels,axis=0)\n",
    "\n",
    "Image_dir = search(\"/home/junhyun/Data/Dataset/grapes\")\n",
    "grapes_images = Image_search(Image_dir,len(Image_dir))\n",
    "grapes_labels = np.ones(len(grapes_images))*2\n",
    "\n",
    "Total_images = np.append(Total_images,grapes_images,axis=0)\n",
    "Total_labels = np.append(Total_labels,grapes_labels,axis=0)\n",
    "\n",
    "Image_dir = search(\"/home/junhyun/Data/Dataset/Leopards\")\n",
    "leopards_images = Image_search(Image_dir,len(Image_dir))\n",
    "leopards_labels = np.ones(len(leopards_images))*3\n",
    "\n",
    "Total_images = np.append(Total_images,leopards_images,axis=0)\n",
    "Total_labels = np.append(Total_labels,leopards_labels,axis=0)\n",
    "\n",
    "Image_dir = search(\"/home/junhyun/Data/Dataset/Motorbikes\")\n",
    "motorbikes_images = Image_search(Image_dir,300)\n",
    "motorbikes_labels = np.ones(len(motorbikes_images))*4\n",
    "\n",
    "Total_images = np.append(Total_images,motorbikes_images,axis=0)\n",
    "Total_labels = np.append(Total_labels,motorbikes_labels,axis=0)\n",
    "\n",
    "Image_dir = search(\"/home/junhyun/Data/Dataset/watch\")\n",
    "watch_images = Image_search(Image_dir,len(Image_dir))\n",
    "watch_labels = np.ones(len(watch_images))*5\n",
    "\n",
    "Total_images = np.append(Total_images,watch_images,axis=0)\n",
    "Total_labels = np.append(Total_labels,watch_labels,axis=0)\n",
    "\n",
    "Image_dir = search(\"/home/junhyun/Data/Dataset/Faces_easy\")\n",
    "faces_easy_images = Image_search(Image_dir,300)\n",
    "faces_easy_labels = np.ones(len(faces_easy_images))*6\n",
    "\n",
    "Total_images = np.append(Total_images,faces_easy_images,axis=0)[1:]\n",
    "Total_labels = np.append(Total_labels,faces_easy_labels,axis=0)[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Total_one_hot = Total_labels.astype(int)\n",
    "Total_one_hot = label2onehot(np.transpose(Total_one_hot),7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shuffle_img_label(img,label):\n",
    "    tmp_img = np.zeros_like(img)\n",
    "    tmp_label = np.zeros_like(label)\n",
    "    Order = list(range(0,len(label)))\n",
    "    np.random.shuffle(Order)\n",
    "    for idx,order in enumerate(Order):\n",
    "        tmp_img[idx] = img[order]\n",
    "        tmp_label[idx] = label[order]\n",
    "    return tmp_img, tmp_label\n",
    "\n",
    "Shuffle_image, Shuffle_label = shuffle_img_label(Total_images,Total_one_hot)\n",
    "# Shuffle_image, Shuffle_label = shuffle_img_label(Total_images,Total_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RGB_flip_LeftRight(Img):\n",
    "    \n",
    "    Img_clone = copy(Img)\n",
    "    Flip_Img_result = np.zeros_like(Img_clone)\n",
    "\n",
    "    for i in range(Img_clone.shape[0]):\n",
    "        Flip_Img = np.reshape(Img_clone[i,:],[200,200,3])\n",
    "    \n",
    "        for k in range(3):\n",
    "            for j in range(Flip_Img.shape[0]):            \n",
    "                Flip_Img[j,:,k] = Flip_Img[j,::-1,k]\n",
    "    \n",
    "    Flip_Img = np.reshape(Flip_Img,[1,200*200*3])\n",
    "    Flip_Img_result[i,:] = Flip_Img\n",
    "\n",
    "    return Flip_Img_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Train_images = Shuffle_image[0:1500]\n",
    "Train_one_hot = Shuffle_label[0:1500]\n",
    "\n",
    "# Flip_images = RGB_flip_LeftRight(Train_images)\n",
    "\n",
    "# Train_images = np.append(Train_images,Flip_images,axis=0)\n",
    "# Train_one_hot = np.append(Train_one_hot,Train_one_hot,axis=0)\n",
    "\n",
    "\n",
    "Test_images = Shuffle_image[1500:]\n",
    "Test_one_hot = Shuffle_label[1500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs=100\n",
    "batch_size=10\n",
    "learning_rate=0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, sess, name):\n",
    "        self.sess=sess\n",
    "        self.name=name\n",
    "        self._build_net()\n",
    "        \n",
    "    def _build_net(self):\n",
    "        self.training= tf.placeholder(tf.bool)\n",
    "        self.X = tf.placeholder(tf.float32,[None, 200*200*3])\n",
    "        X_img = tf.reshape(self.X, [-1,200,200,3])\n",
    "        self.Y = tf.placeholder(tf.float32,[None,7])\n",
    "        \n",
    "        \n",
    "#         self.W1 = tf.Variable(tf.random_normal([3, 3, 3, 64], stddev=0.01))\n",
    "        \n",
    "#         L1 = tf.nn.conv2d(X_img, self.W1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "#         L1 = tf.nn.relu(L1)\n",
    "        \n",
    "        self.conv_W = tf.layers.conv2d(inputs = X_img, \\\n",
    "                                       filters = 64, \\\n",
    "                                       kernel_size=[3, 3], \\\n",
    "                                       padding = \"SAME\",\\\n",
    "                                       activation=tf.nn.relu,\\\n",
    "                                       kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "        \n",
    "        conv1 = tf.layers.conv2d(inputs = self.conv_W, filters = 64, kernel_size=[3, 3], padding = \"SAME\",\\\n",
    "                                 activation=tf.nn.relu,kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "#         conv12 = tf.layers.conv2d(inputs = conv1, filters = 64, kernel_size=[3, 3], padding = \"SAME\",\\\n",
    "#                                   activation=tf.nn.relu,kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "        pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size = [2, 2], padding=\"SAME\", strides=2)\n",
    "#         drop1 = tf.layers.dropout(inputs=pool1, rate=0.7, training = self.training)\n",
    "        \n",
    "        conv2 = tf.layers.conv2d(inputs = pool1, filters = 128, kernel_size=[3, 3], padding = \"SAME\", \\\n",
    "                                 activation=tf.nn.relu,kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "#         conv22 = tf.layers.conv2d(inputs = conv2, filters = 128, kernel_size=[3, 3], padding = \"SAME\", \\\n",
    "#                                   activation=tf.nn.relu,kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "        conv23 = tf.layers.conv2d(inputs = conv2, filters = 128, kernel_size=[3, 3], padding = \"SAME\", \\\n",
    "                                  activation=tf.nn.relu,kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "        pool2 = tf.layers.max_pooling2d(inputs=conv23, pool_size = [2, 2], padding=\"SAME\", strides=2)\n",
    "#         drop2 = tf.layers.dropout(inputs=pool2, rate=0.7, training = self.training)\n",
    "        \n",
    "        conv3 = tf.layers.conv2d(inputs = pool2, filters = 128, kernel_size=[3, 3], padding = \"SAME\", \\\n",
    "                                 activation=tf.nn.relu,kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "#         conv32 = tf.layers.conv2d(inputs = conv3, filters = 128, kernel_size=[3, 3], padding = \"SAME\", \\\n",
    "#                                   activation=tf.nn.relu,kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "        conv33 = tf.layers.conv2d(inputs = conv3, filters = 128, kernel_size=[3, 3], padding = \"SAME\", \\\n",
    "                                  activation=tf.nn.relu,kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "        pool3 = tf.layers.max_pooling2d(inputs=conv33, pool_size = [2, 2], padding=\"SAME\", strides=2)\n",
    "#         drop3 = tf.layers.dropout(inputs=pool3, rate=0.7, training = self.training)\n",
    "        \n",
    "        conv4 = tf.layers.conv2d(inputs = pool3, filters = 256, kernel_size=[3, 3], padding = \"SAME\", \\\n",
    "                                 activation=tf.nn.relu,kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "#         conv42 = tf.layers.conv2d(inputs = conv4, filters = 256, kernel_size=[3, 3], padding = \"SAME\", \\\n",
    "#                                   activation=tf.nn.relu,kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "        conv43 = tf.layers.conv2d(inputs = conv4, filters = 256, kernel_size=[3, 3], padding = \"SAME\", \\\n",
    "                                  activation=tf.nn.relu,kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "        pool4 = tf.layers.max_pooling2d(inputs=conv43, pool_size = [2, 2], padding=\"SAME\", strides=2)\n",
    "#         drop4 = tf.layers.dropout(inputs=pool4, rate=0.7, training = self.training)\n",
    "        \n",
    "        conv5 = tf.layers.conv2d(inputs = pool4, filters = 256, kernel_size=[3, 3], padding = \"SAME\", \\\n",
    "                                 activation=tf.nn.relu,kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "#         conv52 = tf.layers.conv2d(inputs = conv5, filters = 256, kernel_size=[3, 3], padding = \"SAME\", \\\n",
    "#                                   activation=tf.nn.relu,kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "        conv53 = tf.layers.conv2d(inputs = conv5, filters = 256, kernel_size=[3, 3], padding = \"SAME\", \\\n",
    "                                  activation=tf.nn.relu,kernel_initializer=tf.contrib.layers.xavier_initializer())        \n",
    "        pool5 = tf.layers.max_pooling2d(inputs=conv53, pool_size = [2, 2], padding=\"SAME\", strides=2)\n",
    "#         drop5 = tf.layers.dropout(inputs=pool5, rate=0.7, training = self.training)\n",
    "             \n",
    "#         conv6 = tf.layers.conv2d(inputs = pool5, filters = 512, kernel_size=[3, 3], padding = \"SAME\", activation=tf.nn.relu,kernel_initializer=tf.contrib.layers.variance_scaling_initializer(),kernel_regularizer=tf.contrib.layers.l2_regularizer(0.01))\n",
    "#         conv62 = tf.layers.conv2d(inputs = conv6, filters = 512, kernel_size=[3, 3], padding = \"SAME\", activation=tf.nn.relu,kernel_initializer=tf.contrib.layers.variance_scaling_initializer(),kernel_regularizer=tf.contrib.layers.l2_regularizer(0.01))\n",
    "#         conv63 = tf.layers.conv2d(inputs = conv62, filters = 512, kernel_size=[3, 3], padding = \"SAME\", activation=tf.nn.relu,kernel_initializer=tf.contrib.layers.variance_scaling_initializer(),kernel_regularizer=tf.contrib.layers.l2_regularizer(0.01))        \n",
    "#         pool6 = tf.layers.max_pooling2d(inputs=conv63, pool_size = [2, 2], padding=\"SAME\", strides=2)\n",
    "#         drop6 = tf.layers.dropout(inputs=pool6, rate=0.7, training = self.training)\n",
    "             \n",
    "        \n",
    "        flat = tf.reshape(pool5,[-1,7*7*256])\n",
    "        dense4 = tf.layers.dense(inputs=flat,units=4096,activation=tf.nn.relu,\\\n",
    "                                 kernel_initializer = tf.contrib.layers.xavier_initializer(),\\\n",
    "                                 kernel_regularizer=tf.contrib.layers.l2_regularizer(0.001))\n",
    "        drop4 = tf.layers.dropout(inputs=dense4,rate=0.4,training = self.training)\n",
    "        batch4 = tf.layers.batch_normalization(drop4,training= True)\n",
    "        \n",
    "        dense5 = tf.layers.dense(inputs=batch4,units=4096,activation=tf.nn.relu,\\\n",
    "                                 kernel_initializer = tf.contrib.layers.xavier_initializer(),\\\n",
    "                                 kernel_regularizer=tf.contrib.layers.l2_regularizer(0.001))\n",
    "        drop5 = tf.layers.dropout(inputs=dense5,rate=0.4,training = self.training)\n",
    "        batch5 = tf.layers.batch_normalization(drop5,training= True)\n",
    "\n",
    "\n",
    "        dense6 = tf.layers.dense(inputs=batch5,units=1000,activation=tf.nn.relu,\\\n",
    "                                 kernel_initializer = tf.contrib.layers.xavier_initializer(),\\\n",
    "                                 kernel_regularizer=tf.contrib.layers.l2_regularizer(0.001))\n",
    "        drop6 = tf.layers.dropout(inputs=dense6,rate=0.4,training = self.training)\n",
    "        batch6 = tf.layers.batch_normalization(drop6,training= True)\n",
    "        \n",
    "        self.logits = tf.layers.dense(inputs=batch6,units=7,\\\n",
    "                                      kernel_initializer = tf.contrib.layers.xavier_initializer(),\\\n",
    "                                      kernel_regularizer=tf.contrib.layers.l2_regularizer(0.001))\n",
    "        \n",
    "        self.cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=self.logits,labels=self.Y))\n",
    "        self.optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(self.cost)\n",
    "        self.prediction = tf.argmax(self.logits,1)\n",
    "        self.correct_prediction = tf.equal(self.prediction,tf.argmax(self.Y,1))\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "        \n",
    "        \n",
    "    def predict(self,x_test,training=False):\n",
    "        return self.sess.run(self.logits,feed_dict={self.X:x_test, self.training:training})\n",
    "        \n",
    "    def get_accuracy(self, x_test, y_test, training=False):\n",
    "        return self.sess.run(self.accuracy,feed_dict={self.X:x_test, self.Y:y_test, self.training:training})\n",
    "        \n",
    "    def train(self,x_test,y_test,training=True):\n",
    "        return self.sess.run([self.cost,self.optimizer],feed_dict={self.X:x_test,self.Y:y_test, self.training:training})\n",
    "    \n",
    "    def get_weight(self):\n",
    "        Weight = sess.run(self.conv_W.kernel)\n",
    "        return Weight\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session(config=gpu_config)\n",
    "\n",
    "models=[]\n",
    "num_models=1\n",
    "for m in range(num_models):\n",
    "    models.append(Model(sess,\"model\"+str(m)))\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning start!!\n",
      "('epoch : ', '0001', ' cost : ', array([ 2.45472403]))\n",
      "('epoch : ', '0002', ' cost : ', array([ 2.32096274]))\n",
      "('epoch : ', '0003', ' cost : ', array([ 2.22342943]))\n",
      "('epoch : ', '0004', ' cost : ', array([ 2.12498484]))\n",
      "('epoch : ', '0005', ' cost : ', array([ 2.07259195]))\n",
      "('epoch : ', '0006', ' cost : ', array([ 2.02840255]))\n",
      "('epoch : ', '0007', ' cost : ', array([ 2.00850378]))\n",
      "('epoch : ', '0008', ' cost : ', array([ 1.98552188]))\n",
      "('epoch : ', '0009', ' cost : ', array([ 1.97554103]))\n",
      "('epoch : ', '0010', ' cost : ', array([ 1.96624053]))\n",
      "('epoch : ', '0011', ' cost : ', array([ 1.95591268]))\n",
      "('epoch : ', '0012', ' cost : ', array([ 1.95360206]))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-e6e3e54b1824>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mm_idx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_xs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_ys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0mavg_cost_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtotal_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"epoch : \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"%04d\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" cost : \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_cost_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-a660880568ef>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, x_test, y_test, training)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/junhyun/junhyunenv/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/junhyun/junhyunenv/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/junhyun/junhyunenv/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/junhyun/junhyunenv/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1137\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/junhyun/junhyunenv/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Learning start!!\")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    learning_rate = learning_rate*0.99\n",
    "    avg_cost_list = np.zeros(len(models))\n",
    "    total_batch = int(len(Train_one_hot)/batch_size)\n",
    "    for i in range(total_batch):\n",
    "        batch_xs = Train_images[i*batch_size:(i+1)*batch_size]\n",
    "        batch_ys = Train_one_hot[i*batch_size:(i+1)*batch_size]\n",
    "        \n",
    "        for m_idx,m in enumerate(models):\n",
    "            c,_ = m.train(batch_xs,batch_ys)\n",
    "            avg_cost_list[m_idx] += c/total_batch\n",
    "    print(\"epoch : \", \"%04d\"%(epoch+1), \" cost : \", avg_cost_list)\n",
    "    \n",
    "print(\"Learning finished!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 'Accuracy = ', 0.15000001)\n",
      "('Ensemble Accuracy = ', 0.15000001)\n"
     ]
    }
   ],
   "source": [
    "Test_images = Shuffle_image[1600:1620]\n",
    "Test_one_hot = Shuffle_label[1600:1620]\n",
    "\n",
    "test_size = len(Test_one_hot)\n",
    "prediction = np.zeros(test_size*7).reshape(test_size,7)\n",
    "\n",
    "for m_idx,m in enumerate(models):\n",
    "    print(m_idx, \"Accuracy = \", m.get_accuracy(Test_images,Test_one_hot))\n",
    "    p = m.predict(Test_images)\n",
    "    prediction +=p\n",
    "\n",
    "ensemble_correct = tf.equal(tf.argmax(prediction,1),tf.argmax(Test_one_hot,1))\n",
    "ensemble_accuracy = tf.reduce_mean(tf.cast(ensemble_correct,tf.float32))\n",
    "\n",
    "print(\"Ensemble Accuracy = \", sess.run(ensemble_accuracy) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.37547606, -0.19694741, -0.11751966, -0.47925732,  0.1947269 ,\n",
       "        -0.26461226,  0.23582894],\n",
       "       [ 0.37547606, -0.19694741, -0.11751966, -0.47925732,  0.1947269 ,\n",
       "        -0.26461226,  0.23582894],\n",
       "       [ 0.37547606, -0.19694741, -0.11751966, -0.47925732,  0.1947269 ,\n",
       "        -0.26461226,  0.23582894],\n",
       "       [ 0.37547606, -0.19694741, -0.11751966, -0.47925732,  0.1947269 ,\n",
       "        -0.26461226,  0.23582894],\n",
       "       [ 0.37547606, -0.19694741, -0.11751966, -0.47925732,  0.1947269 ,\n",
       "        -0.26461226,  0.23582894],\n",
       "       [ 0.37547606, -0.19694741, -0.11751966, -0.47925732,  0.1947269 ,\n",
       "        -0.26461226,  0.23582894],\n",
       "       [ 0.37547606, -0.19694741, -0.11751966, -0.47925732,  0.1947269 ,\n",
       "        -0.26461226,  0.23582894],\n",
       "       [ 0.37547606, -0.19694741, -0.11751966, -0.47925732,  0.1947269 ,\n",
       "        -0.26461226,  0.23582894],\n",
       "       [ 0.37547606, -0.19694741, -0.11751966, -0.47925732,  0.1947269 ,\n",
       "        -0.26461226,  0.23582894],\n",
       "       [ 0.37547606, -0.19694741, -0.11751966, -0.47925732,  0.1947269 ,\n",
       "        -0.26461226,  0.23582894],\n",
       "       [ 0.37547606, -0.19694741, -0.11751966, -0.47925732,  0.1947269 ,\n",
       "        -0.26461226,  0.23582894],\n",
       "       [ 0.37547606, -0.19694741, -0.11751966, -0.47925732,  0.1947269 ,\n",
       "        -0.26461226,  0.23582894],\n",
       "       [ 0.37547606, -0.19694741, -0.11751966, -0.47925732,  0.1947269 ,\n",
       "        -0.26461226,  0.23582894],\n",
       "       [ 0.37547606, -0.19694741, -0.11751966, -0.47925732,  0.1947269 ,\n",
       "        -0.26461226,  0.23582894],\n",
       "       [ 0.37547606, -0.19694741, -0.11751966, -0.47925732,  0.1947269 ,\n",
       "        -0.26461226,  0.23582894],\n",
       "       [ 0.37547606, -0.19694741, -0.11751966, -0.47925732,  0.1947269 ,\n",
       "        -0.26461226,  0.23582894],\n",
       "       [ 0.37547606, -0.19694741, -0.11751966, -0.47925732,  0.1947269 ,\n",
       "        -0.26461226,  0.23582894],\n",
       "       [ 0.37547606, -0.19694741, -0.11751966, -0.47925732,  0.1947269 ,\n",
       "        -0.26461226,  0.23582894],\n",
       "       [ 0.37547606, -0.19694741, -0.11751966, -0.47925732,  0.1947269 ,\n",
       "        -0.26461226,  0.23582894],\n",
       "       [ 0.37547606, -0.19694741, -0.11751966, -0.47925732,  0.1947269 ,\n",
       "        -0.26461226,  0.23582894]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models[0].predict(Test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'kernel'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-3aee89120505>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mconvWeight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mOrigin_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTest_image\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mWeight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvWeight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-a660880568ef>\u001b[0m in \u001b[0;36mget_weight\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0mWeight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_W\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mWeight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'kernel'"
     ]
    }
   ],
   "source": [
    "convWeight = sess.run(tf.transpose(models[0].get_weight()))\n",
    "Origin_data = Test_image[15][0:1024]\n",
    "Weight = convWeight[3][0]\n",
    "32*32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Origin_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Origin_image = np.reshape(Origin_data,[32,32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.misc\n",
    "\n",
    "i_width = 300\n",
    "i_height = 300\n",
    "\n",
    "Big_image = scipy.misc.imresize(Origin_image, (i_height, i_width))\n",
    "print(Big_image.shape)\n",
    "Origin_image = Big_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "toimage(Origin_image).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Conv_image = signal.convolve2d(Origin_image,Weight,'same')\n",
    "\n",
    "Conv_image -= Conv_image.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "toimage(Conv_image).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(Origin_image.max())\n",
    "print(Origin_image.min())\n",
    "\n",
    "print(Conv_image.max())\n",
    "print(Conv_image.min())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Edge_image = Origin_image-3*Conv_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(Edge_image.max())\n",
    "print(Edge_image.min())\n",
    "Edge_image -= Edge_image.min()\n",
    "Edge_image = Edge_image/Edge_image.max()\n",
    "print(Edge_image.max())\n",
    "print(Edge_image.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "toimage(Edge_image).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "toimage(Weight).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow kernel",
   "language": "python",
   "name": "tfkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
